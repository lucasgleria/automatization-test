# üß© PLANEJAMENTO COMPLETO ‚Äì INTEGRA√á√ÉO DE WORKFLOW CHATGPT + GEMINI

*(Execu√ß√£o local via terminal ‚Äì coleta, an√°lise e estudo final automatizados)*

---

## 1. üéØ Objetivo Geral

Criar um **workflow automatizado** que utiliza **duas IAs** de forma complementar:

* **ChatGPT (OpenAI)** ‚Üí respons√°vel por **buscar, coletar e organizar informa√ß√µes** provenientes exclusivamente de uma lista pr√©-definida de fontes confi√°veis.
* **Gemini (Google)** ‚Üí respons√°vel por **interpretar, analisar e redigir um estudo final completo** com base nos arquivos produzidos pelo ChatGPT.

Tudo isso dever√° ser executado **localmente**, por meio de **um √∫nico comando de terminal**, com controle total sobre instru√ß√µes, fontes e formato final.

---

## 2. ‚öôÔ∏è Fluxo de Execu√ß√£o (Vis√£o Geral)

### Entrada:

```bash
python run_pipeline.py "Tema ou pergunta principal"
```

### Sa√≠da:

Uma pasta de sess√£o com:

```
data/sessions/{timestamp}/
‚îú‚îÄ 01_raw/           # Dados e notas coletadas pelo ChatGPT
‚îú‚îÄ 02_processed/     # (opcional) Normaliza√ß√£o intermedi√°ria
‚îú‚îÄ 03_final/         # Estudo gerado pelo Gemini
‚îú‚îÄ meta.json         # Metadados e uso de tokens
‚îî‚îÄ task.txt          # Descri√ß√£o original da tarefa
```

E, no terminal, exibi√ß√£o de:

```
ChatGPT: 5k tokens utilizados de 8k tokens
Gemini: 50k tokens utilizados de 80k tokens
```

---

## 3. üß± Estrutura de Pastas e Arquivos

```text
projeto-ia-workflow/
‚îÇ
‚îú‚îÄ config/
‚îÇ   ‚îú‚îÄ chatgpt_config.yaml         # Configura√ß√£o do modelo ChatGPT
‚îÇ   ‚îú‚îÄ gemini_config.yaml          # Configura√ß√£o do modelo Gemini
‚îÇ
‚îú‚îÄ prompts/
‚îÇ   ‚îú‚îÄ chatgpt_system.md           # Instru√ß√µes gerais do ChatGPT
‚îÇ   ‚îú‚îÄ chatgpt_sources.md          # Regras sobre como usar as fontes
‚îÇ   ‚îú‚îÄ gemini_system.md            # Instru√ß√µes gerais do Gemini
‚îÇ   ‚îú‚îÄ gemini_format.md            # Estrutura e formata√ß√£o do estudo
‚îÇ   ‚îú‚îÄ fontes_confiaveis.md        # Lista de URLs que o ChatGPT deve obrigatoriamente consultar
‚îÇ
‚îú‚îÄ workflow/
‚îÇ   ‚îú‚îÄ chatgpt_stage.py            # Etapa 1 ‚Äì coleta e organiza√ß√£o
‚îÇ   ‚îú‚îÄ gemini_stage.py             # Etapa 2 ‚Äì an√°lise e estudo
‚îÇ   ‚îú‚îÄ orchestrator.py             # Orquestrador das etapas
‚îÇ
‚îú‚îÄ data/
‚îÇ   ‚îú‚îÄ sessions/
‚îÇ       ‚îú‚îÄ {timestamp}/            # Sess√£o individual (gerada a cada execu√ß√£o)
‚îÇ
‚îú‚îÄ .env                            # Chaves das APIs (OPENAI_API_KEY, GOOGLE_API_KEY)
‚îú‚îÄ run_pipeline.py                 # Script principal (entrada √∫nica)
‚îî‚îÄ requirements.txt
```

---

## 4. üîÑ Fluxo L√≥gico de Execu√ß√£o

### 4.1. Orquestrador (`workflow/orchestrator.py`)

Respons√°vel por:

1. Criar o ID da sess√£o.
2. Criar a estrutura de pastas da sess√£o.
3. Salvar a tarefa original (`task.txt`).
4. Executar em sequ√™ncia:

   * `run_chatgpt_stage(...)`
   * `run_gemini_stage(...)`
5. Exibir e registrar a contagem de tokens.
6. Salvar metadados em `meta.json`.

**Pseudoestrutura:**

```python
def run_pipeline(user_task):
    session_id = create_session_id()
    session_dir = create_session_dir(session_id)

    save_text(session_dir / "task.txt", user_task)

    chatgpt_result, chatgpt_usage = run_chatgpt_stage(user_task, session_dir)
    print(f"ChatGPT: {chatgpt_usage['used_k']:.1f}k tokens utilizados de {chatgpt_usage['max_k']:.1f}k tokens")

    gemini_result, gemini_usage = run_gemini_stage(user_task, session_dir, chatgpt_result)
    print(f"Gemini: {gemini_usage['used_k']:.1f}k tokens utilizados de {gemini_usage['max_k']:.1f}k tokens")

    save_meta(session_dir, user_task, chatgpt_usage, gemini_usage)
```

---

## 5. üß© Etapa 1 ‚Äì ChatGPT (Coleta e Organiza√ß√£o de Informa√ß√µes)

(Esta se√ß√£o permanece inalterada)

---

## 6. üß† Etapa 2 ‚Äì Gemini (Estudo Final)

### Fun√ß√£o:

Elaborar um **estudo anal√≠tico completo** com base nos arquivos produzidos pelo ChatGPT.

### Fontes de entrada:

* `01_raw/summary.md`
* `01_raw/sources.json`
* `01_raw/notes/`

### Sa√≠da esperada:

`03_final/estudo_final.md`

### 6.1. Instru√ß√µes (`gemini_system.md`)

> Seu papel √© **produzir um estudo anal√≠tico** com base nas informa√ß√µes coletadas por outra IA.
>
> * N√£o busque novas fontes.
> * Analise criticamente os dados fornecidos.
> * Identifique converg√™ncias, diverg√™ncias e lacunas.
> * Gere um estudo acad√™mico e claro, conforme o formato definido.

### 6.2. Formata√ß√£o do estudo (`gemini_format.md`)

> Estrutura obrigat√≥ria:
>
> 1. T√≠tulo
> 2. Resumo Executivo
> 3. Introdu√ß√£o
> 4. Contexto Te√≥rico
> 5. An√°lise e Discuss√£o
> 6. Conclus√£o
> 7. Refer√™ncias (Autor ‚Äì T√≠tulo ‚Äì Link ‚Äì Data)

---

## 7. üìä Configura√ß√µes e Limites

### 7.1. ChatGPT

`config/chatgpt_config.yaml` (Inalterado)

### 7.2. Gemini

`config/gemini_config.yaml`

```yaml
model: gemini-1.5-pro-latest
max_context_tokens: 1048576
temperature: 0.4
```

---

## 8. üìÅ Registro de Sess√£o e Logs

Ao final da execu√ß√£o, o arquivo `meta.json` salva todas as informa√ß√µes da sess√£o:

```json
{
  "task": "Impacto da IA no mercado de trabalho brasileiro",
  "chatgpt": {
    "model": "gpt-4o-mini",
    "used_tokens": 5320,
    "max_context_tokens": 8000
  },
  "gemini": {
    "model": "gemini-1.5-pro-latest",
    "used_tokens": 0,
    "max_context_tokens": 1048576
  }
}
```

---

## 9. üíª Execu√ß√£o via Terminal

Exemplo pr√°tico:

```bash
python run_pipeline.py "Impacto da IA na educa√ß√£o b√°sica no Brasil"
```

Sa√≠da esperada:

```
[OK] Sess√£o 2025-11-07_14-33 criada.
[OK] Etapa 1 (ChatGPT) conclu√≠da. Arquivos em data/sessions/2025-11-07_14-33/01_raw
ChatGPT: 5.3k tokens utilizados de 8.0k tokens
[OK] Etapa 2 (Gemini) conclu√≠da. Estudo final em data/sessions/2025-11-07_14-33/03_final/estudo_final.md
Gemini: 0.0k tokens utilizados de 1048.6k tokens
```

---

## 10. üß© Componentes-Chave do Planejamento

| **Componente**         | **Responsabilidade**                                  |
| ---------------------- | ----------------------------------------------------- |
| `run_pipeline.py`      | Ponto √∫nico de entrada via terminal                   |
| `orchestrator.py`      | Coordena as etapas e exibe tokens                     |
| `chatgpt_stage.py`     | Coleta e organiza dados conforme fontes confi√°veis    |
| `gemini_stage.py`      | Produz o estudo final com base nos arquivos coletados |
| `fontes_confiaveis.md` | Lista de URLs obrigat√≥rias e exclusivas               |
| `meta.json`            | Registro de uso de tokens e metadados                 |
| `prompts/*.md`         | Regras expl√≠citas que guiam as decis√µes das IAs       |
| `config/*.yaml`        | Limites e par√¢metros dos modelos                      |

---

## 11. üöÄ Pr√≥ximos Passos

1. Criar os arquivos `prompts/*.md`.
2. Preencher `fontes_confiaveis.md`.
3. Configurar as chaves da API em `.env`.
4. Implementar as fun√ß√µes de cada etapa.
5. Testar o fluxo completo com uma tarefa real.

---

‚úÖ **Resumo final:**
Este sistema cria um **pipeline automatizado, local e controlado**, onde o ChatGPT atua como **coletor de dados confi√°veis** e o Gemini como **sintetizador anal√≠tico**.
