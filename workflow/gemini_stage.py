import os
import json
import yaml
import time
from dotenv import load_dotenv
import google.generativeai as genai
from google.api_core import exceptions

# Load environment variables from .env file
load_dotenv()

def load_prompt(filepath):
    """Loads a prompt from a file."""
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        print(f"Warning: Prompt file not found at {filepath}")
        return ""

def read_chatgpt_outputs(session_dir):
    """Reads all the files generated by the ChatGPT stage."""
    raw_dir = os.path.join(session_dir, "01_raw")

    summary = load_prompt(os.path.join(raw_dir, "summary.md"))

    sources = []
    try:
        with open(os.path.join(raw_dir, "sources.json"), "r", encoding="utf-8") as f:
            sources = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        print("Warning: sources.json not found or is invalid.")

    notes_dir = os.path.join(raw_dir, "notes")
    notes = {}
    if os.path.isdir(notes_dir):
        for filename in os.listdir(notes_dir):
            topic = filename.replace("_", " ").replace(".md", "")
            notes[topic] = load_prompt(os.path.join(notes_dir, filename))

    return summary, sources, notes

def run_gemini_stage(user_task, session_dir, chatgpt_result):
    """
    Runs the Gemini stage to analyze collected data and generate the final study.
    """
    print("Running Gemini stage...")
    max_retries = 3

    # 1. Load configuration
    with open("config/gemini_config.yaml", "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)

    # 2. Configure the Gemini client
    try:
        genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
    except Exception as e:
        print(f"Error configuring Gemini API: {e}")
        return "Error: Could not configure Gemini API.", {
            "model": config.get("model", "unknown"), "used_k": 0, "max_k": 0
        }

    # 3. Load data from the ChatGPT stage
    summary, sources, notes = read_chatgpt_outputs(session_dir)

    # 4. Load Gemini's prompts
    system_instruction = (
        load_prompt("prompts/gemini_system.md") +
        "\\n\\n" +
        load_prompt("prompts/gemini_format.md")
    )

    # 5. Construct the full prompt
    user_prompt_content = (
        f"Here is the research on the topic '{user_task}'. Please generate the final study based on the provided data.\\n\\n"
        f"--- SUMMARY ---\\n{summary}\\n\\n"
        f"--- SOURCES ---\\n{json.dumps(sources, indent=2)}\\n\\n"
        f"--- DETAILED NOTES ---\\n"
    )
    for topic, content in notes.items():
        user_prompt_content += f"Topic: {topic}\\n{content}\\n\\n"

    # 6. Initialize the model and call the API with retry logic
    model = genai.GenerativeModel(
        model_name=config["model"],
        system_instruction=system_instruction
    )

    result = ""
    usage = {}

    for attempt in range(max_retries):
        try:
            response = model.generate_content(user_prompt_content)
            result = response.text
            usage = {
                "model": config["model"], "used_k": 0,
                "max_k": config["max_context_tokens"] / 1000,
                "used_tokens": 0, "max_context_tokens": config["max_context_tokens"],
            }
            break  # Success, exit loop
        except exceptions.ResourceExhausted as e:
            print(f"Rate limit exceeded: {e}")
            retry_after = 60  # Default wait time
            try:
                # Try to parse the recommended retry delay
                if e.retry and hasattr(e.retry, 'delay'):
                     retry_after = e.retry.delay.total_seconds()
            except:
                pass # Use default

            if attempt < max_retries - 1:
                print(f"Waiting for {retry_after:.2f} seconds before retrying...")
                time.sleep(retry_after)
            else:
                print("Max retries reached. Failing.")
                result = "Error: Max retries reached due to rate limiting."
                usage = {"model": config.get("model", "unknown"), "used_k": 0, "max_k": 0}
        except Exception as e:
            print(f"An unexpected error occurred while calling the Gemini API: {e}")
            result = "Error: Could not generate the final study from Gemini API."
            usage = {"model": config.get("model", "unknown"), "used_k": 0, "max_k": 0}
            break

    # 7. Save the final study
    final_dir = os.path.join(session_dir, "03_final")
    os.makedirs(final_dir, exist_ok=True)
    with open(os.path.join(final_dir, "estudo_final.md"), "w", encoding="utf-8") as f:
        f.write(result)

    return result, usage
